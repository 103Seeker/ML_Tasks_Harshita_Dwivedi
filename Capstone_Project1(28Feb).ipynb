{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83e72eb-2357-4251-b4b8-c0e0c3882122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Logistic Regression =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       105\n",
      "           1       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "===== KNN (k=5) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       105\n",
      "           1       0.75      0.73      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "===== Decision Tree (max_depth=4) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       105\n",
      "           1       0.80      0.69      0.74        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.78      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scenario Question: Predicting Titanic Survival\n",
    "# Researchers are studying the Titanic disaster and want to build models that predict whether a\n",
    "#  passenger would survive or not survive based on their information.\n",
    "# - Features used:\n",
    "# - Passenger class (pclass)\n",
    "# - Gender (sex)\n",
    "# - Age (age)\n",
    "# - Number of siblings/spouses aboard (sibsp)\n",
    "# - Number of parents/children aboard (parch)\n",
    "# - Ticket fare (fare)\n",
    "# - Label:\n",
    "# - 1 = Survived\n",
    "# - 0 = Died\n",
    "# The researchers train three different models:\n",
    "# - Logistic Regression\n",
    "# - K-Nearest Neighbors (KNN) with k=5\n",
    "# - Decision Tree with max depth = 4\n",
    "# They then evaluate each model using a classification report (precision, recall, F1-score, accuracy).\n",
    "# Questions for Learners\n",
    "# - Which model performs best at predicting survival, and why?\n",
    "# - How does Logistic Regression differ from Decision Tree in terms of interpretability?\n",
    "# # - Why is scaling applied before training Logistic Regression and KNN, but not strictly needed\n",
    "#  for Decision Trees?\n",
    "# - Looking at the classification report, what do precision and recall mean in the context of survival\n",
    "#  predictions?\n",
    "# - Precision → Of those predicted to survive, how many actually survived?\n",
    "# - Recall → Of all who truly survived, how many were correctly predicted?\n",
    "# - If you were a historian, which model would you trust more to explain survival patterns, and why?\n",
    "\n",
    "# ==============================\n",
    "# Titanic Survival Prediction\n",
    "# ==============================\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'survived']]\n",
    "\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"===== Logistic Regression =====\")\n",
    "print(classification_report(y_test, log_model.predict(X_test_scaled)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"===== KNN (k=5) =====\")\n",
    "print(classification_report(y_test, knn.predict(X_test_scaled)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"===== Decision Tree (max_depth=4) =====\")\n",
    "print(classification_report(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2335e384-f4bc-427f-a065-dc35e51b9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Regression Results =====\n",
      "MAE: 3.2949460373238546\n",
      "R2 Score: 0.9183232069977294\n",
      "\n",
      "===== Classification Results =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         6\n",
      "           1       0.93      0.96      0.95        54\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.71      0.65      0.67        60\n",
      "weighted avg       0.89      0.90      0.89        60\n",
      "\n",
      "\n",
      "===== Cluster Distribution =====\n",
      "cluster\n",
      "2    105\n",
      "0    101\n",
      "1     94\n",
      "Name: count, dtype: int64\n",
      "\n",
      "===== Sample Recommendations =====\n",
      "   exam_score  risk_label  cluster                            intervention\n",
      "0   65.647218           1        1                Time Management Workshop\n",
      "1   60.723676           1        1                Time Management Workshop\n",
      "2   79.357265           1        2  On Track – Encourage Advanced Learning\n",
      "3   64.513298           1        0  On Track – Encourage Advanced Learning\n",
      "4   72.620504           1        0  On Track – Encourage Advanced Learning\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Student Success & Career Path Prediction\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1️⃣ Create Sample Dataset\n",
    "# ------------------------------------------\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "data = {\n",
    "    \"study_hours\": np.random.randint(1, 10, n),\n",
    "    \"attendance\": np.random.randint(50, 100, n),\n",
    "    \"assignments_completion\": np.random.randint(40, 100, n),\n",
    "    \"sleep_hours\": np.random.randint(4, 9, n),\n",
    "    \"stress_level\": np.random.randint(1, 10, n),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate exam score (dependent on features)\n",
    "df[\"exam_score\"] = (\n",
    "    df[\"study_hours\"] * 5 +\n",
    "    df[\"attendance\"] * 0.3 +\n",
    "    df[\"assignments_completion\"] * 0.2 -\n",
    "    df[\"stress_level\"] * 2 +\n",
    "    df[\"sleep_hours\"] * 2 +\n",
    "    np.random.normal(0, 5, n)\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2️⃣ Regression – Predict Exam Score\n",
    "# ------------------------------------------\n",
    "\n",
    "X_reg = df.drop(\"exam_score\", axis=1)\n",
    "y_reg = df[\"exam_score\"]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "y_pred_r = reg_model.predict(X_test_r)\n",
    "\n",
    "print(\"===== Regression Results =====\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test_r, y_pred_r))\n",
    "print(\"R2 Score:\", r2_score(y_test_r, y_pred_r))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3️⃣ Classification – At Risk vs On Track\n",
    "# ------------------------------------------\n",
    "\n",
    "df[\"risk_label\"] = np.where(df[\"exam_score\"] < 40, 0, 1)\n",
    "\n",
    "X_clf = df.drop([\"exam_score\", \"risk_label\"], axis=1)\n",
    "y_clf = df[\"risk_label\"]\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_c_scaled = scaler.fit_transform(X_train_c)\n",
    "X_test_c_scaled = scaler.transform(X_test_c)\n",
    "\n",
    "clf_model = LogisticRegression()\n",
    "clf_model.fit(X_train_c_scaled, y_train_c)\n",
    "\n",
    "y_pred_c = clf_model.predict(X_test_c_scaled)\n",
    "\n",
    "print(\"\\n===== Classification Results =====\")\n",
    "print(classification_report(y_test_c, y_pred_c))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4️⃣ Clustering – Study Habit Groups\n",
    "# ------------------------------------------\n",
    "\n",
    "X_cluster = df[[\"study_hours\", \"attendance\", \"stress_level\"]]\n",
    "\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df[\"cluster\"] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "print(\"\\n===== Cluster Distribution =====\")\n",
    "print(df[\"cluster\"].value_counts())\n",
    "\n",
    "def recommend_intervention(row):\n",
    "    if row[\"risk_label\"] == 0 and row[\"attendance\"] < 70:\n",
    "        return \"Extra Tutoring\"\n",
    "    elif row[\"stress_level\"] > 7:\n",
    "        return \"Counseling\"\n",
    "    elif row[\"assignments_completion\"] < 60:\n",
    "        return \"Time Management Workshop\"\n",
    "    else:\n",
    "        return \"On Track – Encourage Advanced Learning\"\n",
    "\n",
    "df[\"intervention\"] = df.apply(recommend_intervention, axis=1)\n",
    "\n",
    "print(df[[\"exam_score\", \"risk_label\", \"cluster\", \"intervention\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e202b5-38e3-4a1d-93b9-1fe21bcb66c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
